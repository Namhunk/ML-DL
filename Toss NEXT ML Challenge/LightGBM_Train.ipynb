{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4447bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import sklearn\n",
    "import gc\n",
    "import lightgbm as lgb\n",
    "\n",
    "import optuna\n",
    "from optuna.integration import LightGBMPruningCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab74b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score 계산\n",
    "def calculate_weighted_logloss(y_true, y_pred, eps=1e-15):\n",
    "    y_pred = np.clip(y_pred, eps, 1 - eps)\n",
    "    \n",
    "    mask_0 = (y_true == 0)\n",
    "    mask_1 = (y_true == 1)\n",
    "    \n",
    "    ll_0 = -np.mean(np.log(1 - y_pred[mask_0])) if mask_0.sum() > 0 else 0\n",
    "    ll_1 = -np.mean(np.log(y_pred[mask_1])) if mask_1.sum() > 0 else 0\n",
    "    \n",
    "    return 0.5 * ll_0 + 0.5 * ll_1\n",
    "\n",
    "def calculate_competition_score(y_true, y_pred):\n",
    "    ap = average_precision_score(y_true, y_pred)\n",
    "    wll = calculate_weighted_logloss(y_true, y_pred)\n",
    "    score = 0.5 * ap + 0.5 * (1 / (1 + wll))\n",
    "    return score, ap, wll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cdbaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'SEED': 42, # Seed 고정\n",
    "    'VALIDATION_SIZE': 0.2,\n",
    "    'LGB_EARLY_STOPPING': 300, # LGB 조기 종료 설정\n",
    "    'OPTUNA_TRIALS': 50,  # Optuna trials 횟수\n",
    "    'N_SPLITS': 3, # Fold 횟수\n",
    "    'LGB_SEEDS': [42, 2024, 1004] # LGB를 수행할 각 Seed\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5241e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "all_train = pl.read_parquet('./train.parquet')\n",
    "\n",
    "# clicked == 1 데이터 필터링\n",
    "clicked_1 = all_train.filter(pl.col('clicked') == 1)\n",
    "\n",
    "# clicked == 0 데이터 다운샘플링 clicked : non-clicked = 1 : 3\n",
    "clicked_0 = all_train.filter(pl.col('clicked') == 0).sample(n=clicked_1.height * 3, seed=CFG['SEED'])\n",
    "\n",
    "# 두 데이터프레임 합치기\n",
    "train = pl.concat([clicked_1, clicked_0])\n",
    "\n",
    "# 최종 데이터프레임 전체 셔플\n",
    "train = train.sample(fraction=1, shuffle=True, seed=CFG['SEED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9f9810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical, numerical 분류\n",
    "target_col = 'clicked'\n",
    "cols_to_drop = ['seq', 'clicked']\n",
    "cat_cols = ['gender', 'age_group', 'inventory_id', 'day_of_week', 'hour']\n",
    "features = [col for col in train.columns if col not in cols_to_drop]\n",
    "numeric_cols = [col for col in features if col not in cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506d5aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pd = train.to_pandas() # pandas로 변환\n",
    "X = train_pd[features].copy() \n",
    "y = train_pd[target_col]\n",
    "\n",
    "X[cat_cols] = X[cat_cols].astype('category') # category 타입으로 변환\n",
    "X[numeric_cols] = X[numeric_cols].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a953b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optuna에 수행할 train, val 분할\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=CFG['VALIDATION_SIZE'],\n",
    "    random_state=CFG['SEED'],\n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb52f301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_weight 설정\n",
    "pos_count = (y == 1).sum()\n",
    "neg_count = (y == 0).sum()\n",
    "pos_weight_value = neg_count / pos_count if pos_count > 0 else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d6d55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.Trial):\n",
    "    \"\"\"Optuna가 최적화할 목적 함수\"\"\"\n",
    "    # 하이퍼파라미터 탐색 공간 정의\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'device': 'cpu',\n",
    "        'seed': CFG['SEED'],\n",
    "        'num_threads': -1,\n",
    "        'verbosity': -1,\n",
    "        'scale_pos_weight': pos_weight_value,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'feature_pre_filter': False,\n",
    "        \n",
    "        # 튜닝할 하이퍼파라미터들\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 128, 320),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.05, log=True),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 0.9),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-2, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-2, 10.0, log=True),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 200, 1000),\n",
    "    }\n",
    "    print(f\"--- Trial {trial.number} Parameters ---\")\n",
    "    print(params)\n",
    "    print(\"---------------------------------\")\n",
    "\n",
    "    # Pruning Callback (성능이 좋지 않은 trial 조기 중단)\n",
    "    pruning_callback = LightGBMPruningCallback(trial, 'auc',valid_name='valid_1')\n",
    "    lgb_train = lgb.Dataset(X_train, y_train, feature_name=features, categorical_feature=cat_cols)\n",
    "    lgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train, feature_name=features, categorical_feature=cat_cols)\n",
    "\n",
    "    # 모델 학습\n",
    "    bst = lgb.train(\n",
    "        params,\n",
    "        lgb_train,\n",
    "        num_boost_round=100000,\n",
    "        valid_sets=[lgb_train, lgb_eval],\n",
    "        callbacks=[lgb.log_evaluation(period=1000), lgb.early_stopping(CFG['LGB_EARLY_STOPPING'], verbose=True), pruning_callback]\n",
    "    )\n",
    "    auc = bst.best_score['valid_1']['auc']\n",
    "    trial.set_user_attr('best_iteration', bst.best_iteration)\n",
    "\n",
    "    del lgb_train, lgb_eval, bst\n",
    "\n",
    "    # 검증 데이터 AUC 점수 반환\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ca6b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner(n_warmup_steps=10000))\n",
    "study.optimize(objective, n_trials=CFG['OPTUNA_TRIALS'], show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9878509e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n==================================\")\n",
    "print(\"Optuna 최종 최적 결과 (완료된 Trial 기준)\")\n",
    "print(\"==================================\")\n",
    "print(f\"최고 점수 (AUC): {study.best_value:.5f}\")\n",
    "print(\"최적 하이퍼파라미터:\")\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"  '{key}': {value}\")\n",
    "print(f\"해당 Trial 번호: {study.best_trial.number}\")\n",
    "print(\"==================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f13bd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optuna로 탐색한 파라미터(Trial 50)\n",
    "#   'num_leaves': 190, \n",
    "#   'learning_rate': 0.0016691651006236685, \n",
    "#   'colsample_bytree': 0.686387931453528, \n",
    "#   'subsample': 0.6314368795644892, \n",
    "#   'reg_alpha': 3.113738376402282, \n",
    "#   'reg_lambda': 0.0654507771673197, \n",
    "#   'min_child_samples': 468,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccbef31",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_preds = np.zeros((len(X), len(CFG['LGB_SEEDS'])))\n",
    "models = []\n",
    "\n",
    "LGB_params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'num_threads': -1,\n",
    "    'scale_pos_weight': pos_weight_value,\n",
    "    'num_leaves': 190, \n",
    "    'learning_rate': 0.0016691651006236685, \n",
    "    'colsample_bytree': 0.686387931453528, \n",
    "    'subsample': 0.6314368795644892, \n",
    "    'reg_alpha': 3.113738376402282, \n",
    "    'reg_lambda': 0.0654507771673197, \n",
    "    'min_child_samples': 468,\n",
    "    'verbosity': -1\n",
    "}\n",
    "oof_preds = np.zeros((len(X), len(CFG['LGB_SEEDS'])))\n",
    "os.makedirs('lgbm_models', exist_ok=True) # model 저장 폴더 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfdc4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for seed_idx, seed in enumerate(CFG['LGB_SEEDS']):\n",
    "    print(f\"===== SEED: {seed} =====\")\n",
    "    \n",
    "    # StratifiedKFold 설정\n",
    "    skf = StratifiedKFold(n_splits=CFG['N_SPLITS'], shuffle=True, random_state=seed)\n",
    "    \n",
    "    # StratifiedKFold 교차 검증 루프\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        print(f\"--- Fold: {fold+1}/{CFG['N_SPLITS']} ---\")\n",
    "        \n",
    "        # 데이터 분할\n",
    "        X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "        X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n",
    "        \n",
    "        # 파라미터에 현재 시드 적용\n",
    "        params = LGB_params.copy()\n",
    "        params['seed'] = seed\n",
    "        \n",
    "        # LightGBM 데이터셋 생성\n",
    "        lgb_train = lgb.Dataset(X_train, y_train, categorical_feature=cat_cols)\n",
    "        lgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train, categorical_feature=cat_cols)\n",
    "        \n",
    "        # 모델 학습\n",
    "        model = lgb.train(\n",
    "            params=params,\n",
    "            train_set=lgb_train,\n",
    "            valid_sets=[lgb_train, lgb_eval],\n",
    "            num_boost_round=10000,\n",
    "            callbacks=[lgb.early_stopping(CFG['LGB_EARLY_STOPPING'], verbose=False)]\n",
    "        )\n",
    "        \n",
    "        # OOF 예측값 저장\n",
    "        oof_preds[val_idx, seed_idx] = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "        \n",
    "        model_path = f'lgbm_models/lgbm_seed_{seed}_fold_{fold}.joblib' # 각 seed, fold 별 모델 저장\n",
    "        joblib.dump(model, model_path)\n",
    "\n",
    "        del X_train, y_train, X_val, y_val, lgb_train, lgb_eval, model\n",
    "        gc.collect() # 가비지 컬렉터 호출\n",
    "        \n",
    "    print(f\"All models for SEED {seed} saved.\")\n",
    "\n",
    "final_oof = oof_preds.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969873e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "score, ap, wll = calculate_competition_score(y, final_oof)\n",
    "print(\"===== 최종 OOF 성능 =====\")\n",
    "print(f\"Competition Score: {score:.6f}\")\n",
    "print(f\"Average Precision: {ap:.6f}\")\n",
    "print(f\"Weighted LogLoss: {wll:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
