{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "62105bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# library import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import optuna\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e3f32761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 함수\n",
    "def _validate_input(answer_df, submission_df):\n",
    "    # ① 컬럼 개수·이름 일치 여부\n",
    "    if len(answer_df.columns) != len(submission_df.columns) or not all(answer_df.columns == submission_df.columns):\n",
    "        raise ValueError(\"The columns of the answer and submission dataframes do not match.\")\n",
    "\n",
    "\n",
    "    # ② 필수 컬럼에 NaN 존재 여부\n",
    "    if submission_df.isnull().values.any():\n",
    "        raise ValueError(\"The submission dataframe contains missing values.\")\n",
    "\n",
    "\n",
    "    # ③ pair 중복 여부\n",
    "    pairs = list(zip(submission_df[\"leading_item_id\"], submission_df[\"following_item_id\"]))\n",
    "    if len(pairs) != len(set(pairs)):\n",
    "        raise ValueError(\"The submission dataframe contains duplicate (leading_item_id, following_item_id) pairs.\")\n",
    "        \n",
    "def comovement_f1(answer_df, submission_df):\n",
    "    \"\"\"공행성쌍 F1 계산\"\"\"\n",
    "    ans = answer_df[[\"leading_item_id\", \"following_item_id\"]].copy()\n",
    "    sub = submission_df[[\"leading_item_id\", \"following_item_id\"]].copy()\n",
    "\n",
    "\n",
    "    ans[\"pair\"] = list(zip(ans[\"leading_item_id\"], ans[\"following_item_id\"]))\n",
    "    sub[\"pair\"] = list(zip(sub[\"leading_item_id\"], sub[\"following_item_id\"]))\n",
    "\n",
    "\n",
    "    G = set(ans[\"pair\"])\n",
    "    P = set(sub[\"pair\"])\n",
    "\n",
    "\n",
    "    tp = len(G & P)\n",
    "    fp = len(P - G)\n",
    "    fn = len(G - P)\n",
    "\n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "\n",
    "    return f1\n",
    "\n",
    "\n",
    "def comovement_nmae(answer_df, submission_df, eps=1e-6):\n",
    "    \"\"\"\n",
    "    전체 U = G ∪ P에 대한 clipped NMAE 계산\n",
    "    \"\"\"\n",
    "    ans = answer_df[[\"leading_item_id\", \"following_item_id\", \"value\"]].copy()\n",
    "    sub = submission_df[[\"leading_item_id\", \"following_item_id\", \"value\"]].copy()\n",
    "\n",
    "\n",
    "    ans[\"pair\"] = list(zip(ans[\"leading_item_id\"], ans[\"following_item_id\"]))\n",
    "    sub[\"pair\"] = list(zip(sub[\"leading_item_id\"], sub[\"following_item_id\"]))\n",
    "\n",
    "\n",
    "    G = set(ans[\"pair\"])\n",
    "    P = set(sub[\"pair\"])\n",
    "    U = G | P\n",
    "\n",
    "\n",
    "    ans_val = dict(zip(ans[\"pair\"], ans[\"value\"]))\n",
    "    sub_val = dict(zip(sub[\"pair\"], sub[\"value\"]))\n",
    "\n",
    "\n",
    "    errors = []\n",
    "    for pair in U:\n",
    "        if pair in G and pair in P:\n",
    "            # 정수 변환(반올림)\n",
    "            y_true = int(round(float(ans_val[pair])))\n",
    "            y_pred = int(round(float(sub_val[pair])))\n",
    "            rel_err = abs(y_true - y_pred) / (abs(y_true) + eps)\n",
    "            rel_err = min(rel_err, 1.0) # 오차 100% 이상은 100%로 간주\n",
    "        else:\n",
    "            rel_err = 1.0  # FN, FP는 오차 100%\n",
    "        errors.append(rel_err)\n",
    "\n",
    "\n",
    "    return np.mean(errors) if errors else 1.0\n",
    "\n",
    "\n",
    "def comovement_score(answer_df, submission_df):\n",
    "    _validate_input(answer_df, submission_df)\n",
    "    S1 = comovement_f1(answer_df, submission_df)\n",
    "    nmae_full = comovement_nmae(answer_df, submission_df, 1e-6)\n",
    "    S2 = 1 - nmae_full\n",
    "    score = 0.6 * S1 + 0.4 * S2\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d414d4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Load 및 value, weight pivot 생성\n",
    "train = pd.read_csv('./train.csv')\n",
    "\n",
    "# year, month, item_id 기준으로 value 합산 (seq만 다르다면 value 합산)\n",
    "monthly = (\n",
    "    train\n",
    "    .groupby([\"item_id\", \"year\", \"month\"], as_index=False)[[\"value\", 'weight']]\n",
    "    .sum()\n",
    ")\n",
    "\n",
    "# year, month를 하나의 키(ym)로 묶기\n",
    "monthly[\"ym\"] = pd.to_datetime(\n",
    "    monthly[\"year\"].astype(str) + \"-\" + monthly[\"month\"].astype(str).str.zfill(2)\n",
    ")\n",
    "\n",
    "# item_id × ym 피벗 (월별 총 무역량 매트릭스 생성)\n",
    "\n",
    "# value에 대한 pivot\n",
    "pivot_val = (\n",
    "    monthly\n",
    "    .pivot(index=\"item_id\", columns=\"ym\", values=\"value\")\n",
    "    .fillna(0.0)\n",
    ")\n",
    "\n",
    "# weight에 대한 pivot\n",
    "pivot_wgt = (monthly\n",
    "             .pivot(index='item_id', columns='ym', values='weight')\n",
    "             .fillna(0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a26db710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pivot_val\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ym</th>\n",
       "      <th>2022-01-01</th>\n",
       "      <th>2022-02-01</th>\n",
       "      <th>2022-03-01</th>\n",
       "      <th>2022-04-01</th>\n",
       "      <th>2022-05-01</th>\n",
       "      <th>2022-06-01</th>\n",
       "      <th>2022-07-01</th>\n",
       "      <th>2022-08-01</th>\n",
       "      <th>2022-09-01</th>\n",
       "      <th>2022-10-01</th>\n",
       "      <th>...</th>\n",
       "      <th>2024-10-01</th>\n",
       "      <th>2024-11-01</th>\n",
       "      <th>2024-12-01</th>\n",
       "      <th>2025-01-01</th>\n",
       "      <th>2025-02-01</th>\n",
       "      <th>2025-03-01</th>\n",
       "      <th>2025-04-01</th>\n",
       "      <th>2025-05-01</th>\n",
       "      <th>2025-06-01</th>\n",
       "      <th>2025-07-01</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AANGBULD</th>\n",
       "      <td>14276.0</td>\n",
       "      <td>52347.0</td>\n",
       "      <td>53549.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26997.0</td>\n",
       "      <td>84489.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>428725.0</td>\n",
       "      <td>144248.0</td>\n",
       "      <td>26507.0</td>\n",
       "      <td>25691.0</td>\n",
       "      <td>25805.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38441.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>441275.0</td>\n",
       "      <td>533478.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AHMDUILJ</th>\n",
       "      <td>242705.0</td>\n",
       "      <td>120847.0</td>\n",
       "      <td>197317.0</td>\n",
       "      <td>126142.0</td>\n",
       "      <td>71730.0</td>\n",
       "      <td>149138.0</td>\n",
       "      <td>186617.0</td>\n",
       "      <td>169995.0</td>\n",
       "      <td>140547.0</td>\n",
       "      <td>89292.0</td>\n",
       "      <td>...</td>\n",
       "      <td>123085.0</td>\n",
       "      <td>143451.0</td>\n",
       "      <td>78649.0</td>\n",
       "      <td>125098.0</td>\n",
       "      <td>80404.0</td>\n",
       "      <td>157401.0</td>\n",
       "      <td>115509.0</td>\n",
       "      <td>127473.0</td>\n",
       "      <td>89479.0</td>\n",
       "      <td>101317.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANWUJOKX</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63580.0</td>\n",
       "      <td>81670.0</td>\n",
       "      <td>26424.0</td>\n",
       "      <td>8470.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80475.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27980.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>APQGTRMF</th>\n",
       "      <td>383999.0</td>\n",
       "      <td>512813.0</td>\n",
       "      <td>217064.0</td>\n",
       "      <td>470398.0</td>\n",
       "      <td>539873.0</td>\n",
       "      <td>582317.0</td>\n",
       "      <td>759980.0</td>\n",
       "      <td>216019.0</td>\n",
       "      <td>537693.0</td>\n",
       "      <td>205326.0</td>\n",
       "      <td>...</td>\n",
       "      <td>683581.0</td>\n",
       "      <td>2147.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25013.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>20741.0</td>\n",
       "      <td>2403.0</td>\n",
       "      <td>3543.0</td>\n",
       "      <td>32430.0</td>\n",
       "      <td>40608.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATLDMDBO</th>\n",
       "      <td>143097177.0</td>\n",
       "      <td>103568323.0</td>\n",
       "      <td>118403737.0</td>\n",
       "      <td>121873741.0</td>\n",
       "      <td>115024617.0</td>\n",
       "      <td>65716075.0</td>\n",
       "      <td>146216818.0</td>\n",
       "      <td>97552978.0</td>\n",
       "      <td>72341427.0</td>\n",
       "      <td>87454167.0</td>\n",
       "      <td>...</td>\n",
       "      <td>60276050.0</td>\n",
       "      <td>30160198.0</td>\n",
       "      <td>42613728.0</td>\n",
       "      <td>64451013.0</td>\n",
       "      <td>38667429.0</td>\n",
       "      <td>29354408.0</td>\n",
       "      <td>42450439.0</td>\n",
       "      <td>37136720.0</td>\n",
       "      <td>32181798.0</td>\n",
       "      <td>57090235.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ym         2022-01-01   2022-02-01   2022-03-01   2022-04-01   2022-05-01  \\\n",
       "item_id                                                                     \n",
       "AANGBULD      14276.0      52347.0      53549.0          0.0      26997.0   \n",
       "AHMDUILJ     242705.0     120847.0     197317.0     126142.0      71730.0   \n",
       "ANWUJOKX          0.0          0.0          0.0      63580.0      81670.0   \n",
       "APQGTRMF     383999.0     512813.0     217064.0     470398.0     539873.0   \n",
       "ATLDMDBO  143097177.0  103568323.0  118403737.0  121873741.0  115024617.0   \n",
       "\n",
       "ym        2022-06-01   2022-07-01  2022-08-01  2022-09-01  2022-10-01  ...  \\\n",
       "item_id                                                                ...   \n",
       "AANGBULD     84489.0          0.0         0.0         0.0         0.0  ...   \n",
       "AHMDUILJ    149138.0     186617.0    169995.0    140547.0     89292.0  ...   \n",
       "ANWUJOKX     26424.0       8470.0         0.0         0.0     80475.0  ...   \n",
       "APQGTRMF    582317.0     759980.0    216019.0    537693.0    205326.0  ...   \n",
       "ATLDMDBO  65716075.0  146216818.0  97552978.0  72341427.0  87454167.0  ...   \n",
       "\n",
       "ym        2024-10-01  2024-11-01  2024-12-01  2025-01-01  2025-02-01  \\\n",
       "item_id                                                                \n",
       "AANGBULD    428725.0    144248.0     26507.0     25691.0     25805.0   \n",
       "AHMDUILJ    123085.0    143451.0     78649.0    125098.0     80404.0   \n",
       "ANWUJOKX         0.0         0.0         0.0     27980.0         0.0   \n",
       "APQGTRMF    683581.0      2147.0         0.0     25013.0        77.0   \n",
       "ATLDMDBO  60276050.0  30160198.0  42613728.0  64451013.0  38667429.0   \n",
       "\n",
       "ym        2025-03-01  2025-04-01  2025-05-01  2025-06-01  2025-07-01  \n",
       "item_id                                                               \n",
       "AANGBULD         0.0     38441.0         0.0    441275.0    533478.0  \n",
       "AHMDUILJ    157401.0    115509.0    127473.0     89479.0    101317.0  \n",
       "ANWUJOKX         0.0         0.0         0.0         0.0         0.0  \n",
       "APQGTRMF     20741.0      2403.0      3543.0     32430.0     40608.0  \n",
       "ATLDMDBO  29354408.0  42450439.0  37136720.0  32181798.0  57090235.0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# value pivot\n",
    "print('pivot_val')\n",
    "pivot_val.head() # 2022-01 - 2025-07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "542b4e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pivot_wgt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ym</th>\n",
       "      <th>2022-01-01</th>\n",
       "      <th>2022-02-01</th>\n",
       "      <th>2022-03-01</th>\n",
       "      <th>2022-04-01</th>\n",
       "      <th>2022-05-01</th>\n",
       "      <th>2022-06-01</th>\n",
       "      <th>2022-07-01</th>\n",
       "      <th>2022-08-01</th>\n",
       "      <th>2022-09-01</th>\n",
       "      <th>2022-10-01</th>\n",
       "      <th>...</th>\n",
       "      <th>2024-10-01</th>\n",
       "      <th>2024-11-01</th>\n",
       "      <th>2024-12-01</th>\n",
       "      <th>2025-01-01</th>\n",
       "      <th>2025-02-01</th>\n",
       "      <th>2025-03-01</th>\n",
       "      <th>2025-04-01</th>\n",
       "      <th>2025-05-01</th>\n",
       "      <th>2025-06-01</th>\n",
       "      <th>2025-07-01</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AANGBULD</th>\n",
       "      <td>17625.0</td>\n",
       "      <td>67983.0</td>\n",
       "      <td>69544.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34173.0</td>\n",
       "      <td>103666.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>786651.0</td>\n",
       "      <td>249144.0</td>\n",
       "      <td>33133.0</td>\n",
       "      <td>32937.0</td>\n",
       "      <td>33083.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49050.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>865246.0</td>\n",
       "      <td>1046036.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AHMDUILJ</th>\n",
       "      <td>100990.0</td>\n",
       "      <td>43444.0</td>\n",
       "      <td>64113.0</td>\n",
       "      <td>42637.0</td>\n",
       "      <td>21468.0</td>\n",
       "      <td>59424.0</td>\n",
       "      <td>61587.0</td>\n",
       "      <td>63625.0</td>\n",
       "      <td>61245.0</td>\n",
       "      <td>20382.0</td>\n",
       "      <td>...</td>\n",
       "      <td>42986.0</td>\n",
       "      <td>43763.0</td>\n",
       "      <td>24379.0</td>\n",
       "      <td>62351.0</td>\n",
       "      <td>23521.0</td>\n",
       "      <td>43332.0</td>\n",
       "      <td>44913.0</td>\n",
       "      <td>44035.0</td>\n",
       "      <td>25574.0</td>\n",
       "      <td>34463.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANWUJOKX</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89967.0</td>\n",
       "      <td>118992.0</td>\n",
       "      <td>41649.0</td>\n",
       "      <td>13888.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119940.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37211.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>APQGTRMF</th>\n",
       "      <td>50193.0</td>\n",
       "      <td>81429.0</td>\n",
       "      <td>43310.0</td>\n",
       "      <td>62505.0</td>\n",
       "      <td>84680.0</td>\n",
       "      <td>37425.0</td>\n",
       "      <td>114600.0</td>\n",
       "      <td>39305.0</td>\n",
       "      <td>104865.0</td>\n",
       "      <td>43123.0</td>\n",
       "      <td>...</td>\n",
       "      <td>118952.0</td>\n",
       "      <td>698.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1907.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2777.0</td>\n",
       "      <td>347.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>4974.0</td>\n",
       "      <td>6314.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATLDMDBO</th>\n",
       "      <td>163308448.0</td>\n",
       "      <td>113468029.0</td>\n",
       "      <td>131798388.0</td>\n",
       "      <td>118641599.0</td>\n",
       "      <td>106301802.0</td>\n",
       "      <td>63769133.0</td>\n",
       "      <td>148292927.0</td>\n",
       "      <td>101468186.0</td>\n",
       "      <td>77986006.0</td>\n",
       "      <td>94320028.0</td>\n",
       "      <td>...</td>\n",
       "      <td>143545801.0</td>\n",
       "      <td>70368609.0</td>\n",
       "      <td>99495350.0</td>\n",
       "      <td>153804927.0</td>\n",
       "      <td>93762902.0</td>\n",
       "      <td>76888377.0</td>\n",
       "      <td>119375444.0</td>\n",
       "      <td>112349280.0</td>\n",
       "      <td>95457203.0</td>\n",
       "      <td>165713328.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ym         2022-01-01   2022-02-01   2022-03-01   2022-04-01   2022-05-01  \\\n",
       "item_id                                                                     \n",
       "AANGBULD      17625.0      67983.0      69544.0          0.0      34173.0   \n",
       "AHMDUILJ     100990.0      43444.0      64113.0      42637.0      21468.0   \n",
       "ANWUJOKX          0.0          0.0          0.0      89967.0     118992.0   \n",
       "APQGTRMF      50193.0      81429.0      43310.0      62505.0      84680.0   \n",
       "ATLDMDBO  163308448.0  113468029.0  131798388.0  118641599.0  106301802.0   \n",
       "\n",
       "ym        2022-06-01   2022-07-01   2022-08-01  2022-09-01  2022-10-01  ...  \\\n",
       "item_id                                                                 ...   \n",
       "AANGBULD    103666.0          0.0          0.0         0.0         0.0  ...   \n",
       "AHMDUILJ     59424.0      61587.0      63625.0     61245.0     20382.0  ...   \n",
       "ANWUJOKX     41649.0      13888.0          0.0         0.0    119940.0  ...   \n",
       "APQGTRMF     37425.0     114600.0      39305.0    104865.0     43123.0  ...   \n",
       "ATLDMDBO  63769133.0  148292927.0  101468186.0  77986006.0  94320028.0  ...   \n",
       "\n",
       "ym         2024-10-01  2024-11-01  2024-12-01   2025-01-01  2025-02-01  \\\n",
       "item_id                                                                  \n",
       "AANGBULD     786651.0    249144.0     33133.0      32937.0     33083.0   \n",
       "AHMDUILJ      42986.0     43763.0     24379.0      62351.0     23521.0   \n",
       "ANWUJOKX          0.0         0.0         0.0      37211.0         0.0   \n",
       "APQGTRMF     118952.0       698.0         0.0       1907.0        11.0   \n",
       "ATLDMDBO  143545801.0  70368609.0  99495350.0  153804927.0  93762902.0   \n",
       "\n",
       "ym        2025-03-01   2025-04-01   2025-05-01  2025-06-01   2025-07-01  \n",
       "item_id                                                                  \n",
       "AANGBULD         0.0      49050.0          0.0    865246.0    1046036.0  \n",
       "AHMDUILJ     43332.0      44913.0      44035.0     25574.0      34463.0  \n",
       "ANWUJOKX         0.0          0.0          0.0         0.0          0.0  \n",
       "APQGTRMF      2777.0        347.0        335.0      4974.0       6314.0  \n",
       "ATLDMDBO  76888377.0  119375444.0  112349280.0  95457203.0  165713328.0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weight pivot\n",
    "print('pivot_wgt')\n",
    "pivot_wgt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c8d9258e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:05, 19.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "탐색된 공행성쌍 수: 3001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>leading_item_id</th>\n",
       "      <th>following_item_id</th>\n",
       "      <th>best_lag</th>\n",
       "      <th>max_corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AHMDUILJ</td>\n",
       "      <td>APQGTRMF</td>\n",
       "      <td>6</td>\n",
       "      <td>0.419733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AHMDUILJ</td>\n",
       "      <td>ATLDMDBO</td>\n",
       "      <td>4</td>\n",
       "      <td>0.483281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AHMDUILJ</td>\n",
       "      <td>AXULOHBQ</td>\n",
       "      <td>9</td>\n",
       "      <td>0.391992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AHMDUILJ</td>\n",
       "      <td>BJALXPFS</td>\n",
       "      <td>10</td>\n",
       "      <td>0.574470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AHMDUILJ</td>\n",
       "      <td>BSRMSVTC</td>\n",
       "      <td>12</td>\n",
       "      <td>0.479705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  leading_item_id following_item_id  best_lag  max_corr\n",
       "0        AHMDUILJ          APQGTRMF         6  0.419733\n",
       "1        AHMDUILJ          ATLDMDBO         4  0.483281\n",
       "2        AHMDUILJ          AXULOHBQ         9  0.391992\n",
       "3        AHMDUILJ          BJALXPFS        10  0.574470\n",
       "4        AHMDUILJ          BSRMSVTC        12  0.479705"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 선후행 관계인 공행성쌍 추출\n",
    "def safe_corr(x, y):\n",
    "    if np.std(x) == 0 or np.std(y) == 0:\n",
    "        return 0.0\n",
    "    return float(np.corrcoef(x, y)[0, 1])\n",
    "\n",
    "def find_comovement_pairs(pivot, max_lag=12, min_nonzero=36, corr_threshold=0.35):\n",
    "    items = pivot.index.to_list()\n",
    "    months = pivot.columns.to_list()\n",
    "    n_months = len(months)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for i, leader in tqdm(enumerate(items)):\n",
    "        x = pivot.loc[leader].values.astype(float)\n",
    "        if np.count_nonzero(x) < min_nonzero:\n",
    "            continue\n",
    "\n",
    "        for follower in items:\n",
    "            if follower == leader:\n",
    "                continue\n",
    "\n",
    "            y = pivot.loc[follower].values.astype(float)\n",
    "            if np.count_nonzero(y) < min_nonzero:\n",
    "                continue\n",
    "\n",
    "            best_lag = None\n",
    "            best_corr = 0.0\n",
    "\n",
    "            # lag = 1 ~ max_lag 탐색\n",
    "            for lag in range(1, max_lag + 1):\n",
    "                if n_months <= lag:\n",
    "                    continue\n",
    "                corr = safe_corr(x[:-lag], y[lag:])\n",
    "                if abs(corr) > abs(best_corr):\n",
    "                    best_corr = corr\n",
    "                    best_lag = lag\n",
    "\n",
    "            # 임계값 이상이면 공행성쌍으로 채택\n",
    "            if best_lag is not None and abs(best_corr) >= corr_threshold:\n",
    "                results.append({\n",
    "                    \"leading_item_id\": leader,\n",
    "                    \"following_item_id\": follower,\n",
    "                    \"best_lag\": best_lag,\n",
    "                    \"max_corr\": best_corr,\n",
    "                })\n",
    "\n",
    "    pairs = pd.DataFrame(results)\n",
    "    return pairs\n",
    "\n",
    "pairs = find_comovement_pairs(pivot_val)\n",
    "print(\"탐색된 공행성쌍 수:\", len(pairs))\n",
    "pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f786b693",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create Train data: 3001it [00:03, 940.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 학습 데이터의 shape : (105015, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>b_t</th>\n",
       "      <th>b_t_1</th>\n",
       "      <th>b_w_t</th>\n",
       "      <th>b_w_t_1</th>\n",
       "      <th>a_t_lag</th>\n",
       "      <th>a_w_t_lag</th>\n",
       "      <th>max_corr</th>\n",
       "      <th>best_lag</th>\n",
       "      <th>a_hs2</th>\n",
       "      <th>b_hs2</th>\n",
       "      <th>a_hs4</th>\n",
       "      <th>b_hs4</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>759980.0</td>\n",
       "      <td>582317.0</td>\n",
       "      <td>759980.0</td>\n",
       "      <td>582317.0</td>\n",
       "      <td>242705.0</td>\n",
       "      <td>100990.0</td>\n",
       "      <td>0.419733</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21</td>\n",
       "      <td>81</td>\n",
       "      <td>2102</td>\n",
       "      <td>8105</td>\n",
       "      <td>216019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>216019.0</td>\n",
       "      <td>759980.0</td>\n",
       "      <td>216019.0</td>\n",
       "      <td>759980.0</td>\n",
       "      <td>120847.0</td>\n",
       "      <td>43444.0</td>\n",
       "      <td>0.419733</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21</td>\n",
       "      <td>81</td>\n",
       "      <td>2102</td>\n",
       "      <td>8105</td>\n",
       "      <td>537693.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>537693.0</td>\n",
       "      <td>216019.0</td>\n",
       "      <td>537693.0</td>\n",
       "      <td>216019.0</td>\n",
       "      <td>197317.0</td>\n",
       "      <td>64113.0</td>\n",
       "      <td>0.419733</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21</td>\n",
       "      <td>81</td>\n",
       "      <td>2102</td>\n",
       "      <td>8105</td>\n",
       "      <td>205326.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>205326.0</td>\n",
       "      <td>537693.0</td>\n",
       "      <td>205326.0</td>\n",
       "      <td>537693.0</td>\n",
       "      <td>126142.0</td>\n",
       "      <td>42637.0</td>\n",
       "      <td>0.419733</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21</td>\n",
       "      <td>81</td>\n",
       "      <td>2102</td>\n",
       "      <td>8105</td>\n",
       "      <td>169440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>169440.0</td>\n",
       "      <td>205326.0</td>\n",
       "      <td>169440.0</td>\n",
       "      <td>205326.0</td>\n",
       "      <td>71730.0</td>\n",
       "      <td>21468.0</td>\n",
       "      <td>0.419733</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21</td>\n",
       "      <td>81</td>\n",
       "      <td>2102</td>\n",
       "      <td>8105</td>\n",
       "      <td>698033.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time       b_t     b_t_1     b_w_t   b_w_t_1   a_t_lag  a_w_t_lag  \\\n",
       "0     6  759980.0  582317.0  759980.0  582317.0  242705.0   100990.0   \n",
       "1     7  216019.0  759980.0  216019.0  759980.0  120847.0    43444.0   \n",
       "2     8  537693.0  216019.0  537693.0  216019.0  197317.0    64113.0   \n",
       "3     9  205326.0  537693.0  205326.0  537693.0  126142.0    42637.0   \n",
       "4    10  169440.0  205326.0  169440.0  205326.0   71730.0    21468.0   \n",
       "\n",
       "   max_corr  best_lag a_hs2 b_hs2 a_hs4 b_hs4    target  \n",
       "0  0.419733       6.0    21    81  2102  8105  216019.0  \n",
       "1  0.419733       6.0    21    81  2102  8105  537693.0  \n",
       "2  0.419733       6.0    21    81  2102  8105  205326.0  \n",
       "3  0.419733       6.0    21    81  2102  8105  169440.0  \n",
       "4  0.419733       6.0    21    81  2102  8105  698033.0  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습 데이터 생성\n",
    "def build_training_data(pivot_val, pivot_wgt, pairs, df):\n",
    "    \"\"\"\n",
    "    공행성쌍 + 시계열을 이용해 (X, y) 학습 데이터를 만드는 함수\n",
    "    input X:\n",
    "      - b_t, b_t_1, a_t_lag, max_corr, best_lag\n",
    "    target y:\n",
    "      - b_t_plus_1\n",
    "    \"\"\"\n",
    "    months = pivot_val.columns.to_list()\n",
    "    n_months = len(months)\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for row in tqdm(pairs.itertuples(index=False), desc='Create Train data'):\n",
    "        leader = row.leading_item_id\n",
    "        follower = row.following_item_id\n",
    "        lag = int(row.best_lag)\n",
    "        corr = float(row.max_corr)\n",
    "\n",
    "        if leader not in pivot_val.index or follower not in pivot_val.index:\n",
    "            continue\n",
    "\n",
    "        a_series_val = pivot_val.loc[leader].values.astype(float) # value pivot\n",
    "        a_series_wgt = pivot_wgt.loc[leader].values.astype(float) # weight pivot\n",
    "        \n",
    "        a_hs4 = df.loc[df['item_id'] == leader, 'hs4'].unique()[0].astype(str) # 각 품목의 hs4\n",
    "        b_hs4 = df.loc[df['item_id'] == follower, 'hs4'].unique()[0].astype(str) # 각 품목의 hs4\n",
    "\n",
    "        a_hs2 = a_hs4[:2]\n",
    "        b_hs2 = b_hs4[:2]\n",
    "\n",
    "        b_series_val = pivot_val.loc[follower].values.astype(float)\n",
    "        b_series_wgt = pivot_val.loc[follower].values.astype(float)\n",
    "\n",
    "        # t+1이 존재하고, t-lag >= 0인 구간만 학습에 사용\n",
    "        for t in range(max(lag, 1), n_months - 1):\n",
    "            b_t = b_series_val[t] # t 시간인 경우의 value 값\n",
    "            b_t_1 = b_series_val[t - 1] # t-1 시간인 경우의 value값\n",
    "\n",
    "            b_w_t = b_series_wgt[t] # t 시간인 경우의 weight값\n",
    "            b_w_t_1 = b_series_wgt[t-1] # t-1 시간인 경우의 weight값\n",
    "            \n",
    "            a_t_lag = a_series_val[t - lag] # \n",
    "            a_w_t_lag = a_series_wgt[t - lag] # \n",
    "\n",
    "            b_t_plus_1 = b_series_val[t + 1]\n",
    "\n",
    "            rows.append({\n",
    "                'time': t, # 현재 시간\n",
    "                \"b_t\": b_t, \n",
    "                \"b_t_1\": b_t_1,\n",
    "                \"b_w_t\": b_w_t,\n",
    "                \"b_w_t_1\": b_w_t_1,\n",
    "                \"a_t_lag\": a_t_lag,\n",
    "                \"a_w_t_lag\": a_w_t_lag,\n",
    "                \"max_corr\": corr,\n",
    "                \"best_lag\": float(lag),\n",
    "                \"a_hs2\": a_hs2,\n",
    "                \"b_hs2\": b_hs2,\n",
    "                \"a_hs4\": a_hs4,\n",
    "                \"b_hs4\": b_hs4,\n",
    "                \"target\": b_t_plus_1,\n",
    "            })\n",
    "\n",
    "    df_train = pd.DataFrame(rows)\n",
    "    return df_train\n",
    "\n",
    "df_train_model = build_training_data(pivot_val, pivot_wgt, pairs, train) # 데이터 생성\n",
    "df_train_model[['a_hs2', 'b_hs2', 'a_hs4', 'b_hs4']] = df_train_model[['a_hs2', 'b_hs2', 'a_hs4', 'b_hs4']].astype('category') # hs2, hs4\n",
    "print('생성된 학습 데이터의 shape :', df_train_model.shape)\n",
    "df_train_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "955bc8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 105015 entries, 0 to 105014\n",
      "Data columns (total 14 columns):\n",
      " #   Column     Non-Null Count   Dtype   \n",
      "---  ------     --------------   -----   \n",
      " 0   time       105015 non-null  int64   \n",
      " 1   b_t        105015 non-null  float64 \n",
      " 2   b_t_1      105015 non-null  float64 \n",
      " 3   b_w_t      105015 non-null  float64 \n",
      " 4   b_w_t_1    105015 non-null  float64 \n",
      " 5   a_t_lag    105015 non-null  float64 \n",
      " 6   a_w_t_lag  105015 non-null  float64 \n",
      " 7   max_corr   105015 non-null  float64 \n",
      " 8   best_lag   105015 non-null  float64 \n",
      " 9   a_hs2      105015 non-null  category\n",
      " 10  b_hs2      105015 non-null  category\n",
      " 11  a_hs4      105015 non-null  category\n",
      " 12  b_hs4      105015 non-null  category\n",
      " 13  target     105015 non-null  float64 \n",
      "dtypes: category(4), float64(9), int64(1)\n",
      "memory usage: 8.4 MB\n"
     ]
    }
   ],
   "source": [
    "# 각 feature DataType 확인\n",
    "df_train_model.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e0432ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기간의 범위: 1 - 41\n",
      "마지막 달 부터 11개월 전: 30\n",
      "\n",
      "2025-07: 42\n",
      "2025-06: 41\n",
      "2024-07: 30\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터에 대한 정보\n",
    "\n",
    "# 사용할 feature\n",
    "feature_cols = [\"time\", \"b_t\", \"b_t_1\", \"b_w_t\", \"b_w_t_1\", \"a_t_lag\", \"a_w_t_lag\", \"max_corr\", \"best_lag\", \"a_hs2\", \"b_hs2\", \"a_hs4\", \"b_hs4\"]\n",
    "\n",
    "start, end = df_train_model['time'].min(), df_train_model['time'].max()\n",
    "print(f'기간의 범위: {start} - {end}')\n",
    "print(f'마지막 달 부터 11개월 전: {end-11}\\n')\n",
    "print('2025-07: 42')\n",
    "print('2025-06: 41')\n",
    "print('2024-07: 30')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7ee5cb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 지표의 S2 계산 함수(상대 오차)\n",
    "def calculate_custom_error(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    상대 오차(Relative Error) 계산 로직\n",
    "    \"\"\"\n",
    "    # 음수 예측 보정\n",
    "    y_pred = np.maximum(y_pred, 0)\n",
    "    \n",
    "    eps = 1e-6\n",
    "    diff = np.abs(y_true - y_pred)\n",
    "    denom = np.abs(y_true) + eps\n",
    "    \n",
    "    rel_err = diff / denom\n",
    "    bounded_err = np.minimum(rel_err, 1.0)\n",
    "    \n",
    "    return np.mean(bounded_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fe859b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2024-07 부터 2024-06 까지 훈련과 검증을 수행하는 함수\n",
    "def train_validation_with_fold(df, feats, base_model, model_type):\n",
    "    end = df['time'].max() # 마지막 달 6월\n",
    "    start = end-11 # 시작 달 7월\n",
    "    fold_scores = [] # 각 fold의 점수\n",
    "    for vtime in range(start, end+1):\n",
    "        # 훈련 데이터\n",
    "        x_tr, y_tr = df.loc[df['time'] < vtime, feats], df.loc[df['time'] < vtime, 'target']\n",
    "\n",
    "        # 검증 데이터\n",
    "        x_val, y_val = df.loc[df['time'] == vtime, feats], df.loc[df['time'] == vtime, 'target']\n",
    "        \n",
    "        # 최근 데이터일수록 큰 가중치 부여\n",
    "        min_time = x_tr['time'].min()\n",
    "        max_time = x_tr['time'].max()\n",
    "        norm_time = (x_tr['time'] - min_time) / (max_time - min_time)\n",
    "        sample_weight = np.exp(norm_time*3)\n",
    "\n",
    "        fit_params = {}\n",
    "        # 모델 Type 별 fit 입력 값\n",
    "        if model_type == 'lgb': # LightGBM\n",
    "            fit_params = {\n",
    "                'eval_set': [(x_val, y_val)],\n",
    "                'sample_weight': sample_weight,\n",
    "                'callbacks': [lgb.early_stopping(stopping_rounds=50, verbose=False)]\n",
    "            }\n",
    "\n",
    "        elif model_type == 'xgb': # XGBoost\n",
    "            fit_params = {\n",
    "                'eval_set': [(x_val, y_val)],\n",
    "                'sample_weight': sample_weight,\n",
    "                'verbose': False\n",
    "            }\n",
    "\n",
    "        elif model_type == 'hgb': # Histogram Gradient Boost\n",
    "            fit_params = {\n",
    "                'sample_weight': sample_weight\n",
    "            }\n",
    "        \n",
    "        base_model.fit(x_tr, y_tr, **fit_params)\n",
    "\n",
    "        preds = base_model.predict(x_val) # 추론\n",
    "        \n",
    "        score = calculate_custom_error(y_val, preds) # 검증에 대한 점수\n",
    "        fold_scores.append(score)\n",
    "\n",
    "\n",
    "    return np.mean(fold_scores) # 각 fold의 점수에 대한 점수 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a1933987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optuna를 통한 하이퍼 파라미터 최적화 함수\n",
    "def objective(trial, df, feats, seed, model_type):\n",
    "    cat_cols = ['a_hs2', 'b_hs2', 'a_hs4', 'b_hs4']\n",
    "    model = None\n",
    "    if model_type == 'lgb':\n",
    "        params = {\n",
    "            'objective': 'regression',\n",
    "            'verbosity': -1,\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 400, 2000),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.1, log=True),\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 10, 200),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "            'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 1e-3, 10.0, log=True),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 1e-3, 10.0, log=True),\n",
    "            'random_state': seed,\n",
    "            'n_jobs': -1\n",
    "        }\n",
    "        model = LGBMRegressor(**params)\n",
    "\n",
    "    elif model_type == 'xgb':\n",
    "        params = {\n",
    "            'objective': 'reg:squarederror',\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 400, 2000),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.1, log=True),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "            'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 1e-3, 10.0, log=True),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 1e-3, 10.0, log=True),\n",
    "            'early_stopping_rounds': 50, \n",
    "            'random_state': seed,\n",
    "            'n_jobs': -1,\n",
    "            'enable_categorical': True, \n",
    "            'tree_method': 'hist'\n",
    "        }\n",
    "        model = XGBRegressor(**params)\n",
    "\n",
    "    elif model_type == 'hgb':\n",
    "        is_categorical = [f in cat_cols for f in feats]\n",
    "        params = {\n",
    "            'loss': 'squared_error',\n",
    "            'max_iter': trial.suggest_int('max_iter', 400, 2000),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.1, log=True),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "            'max_leaf_nodes': trial.suggest_int('max_leaf_nodes', 10, 200),\n",
    "            'l2_regularization': trial.suggest_float('l2_regularization', 1e-3, 10.0, log=True),\n",
    "            'categorical_features': is_categorical, # Boolean Mask 전달\n",
    "            'random_state': seed\n",
    "        }\n",
    "        model = HistGradientBoostingRegressor(**params)\n",
    "\n",
    "    score = train_validation_with_fold(df, feats, model, model_type) # fold 점수 반환\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "22a5d600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 SEED 별 최적의 하이퍼 파라미터 탐색 -- ## 수정 각 모델마다 1개의 SEED 사용 ##\n",
    "def training_with_seed(df, feats, model_type):\n",
    "    optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "    SEED = [1]\n",
    "    trials = 20\n",
    "    \n",
    "    # objective 함수 내에 있던 cat_cols 정보 (HGB 마스크 생성용)\n",
    "    cat_cols = ['a_hs2', 'b_hs2', 'a_hs4', 'b_hs4']\n",
    "\n",
    "    Scores = []\n",
    "    Params = []\n",
    "    \n",
    "    print(f'{model_type} 모델 (SEED {len(SEED)}개: {SEED}), Trial = {trials}')\n",
    "    \n",
    "    for seed in SEED:\n",
    "        # 1. 최적화 수행\n",
    "        study = optuna.create_study(direction='minimize', study_name='Optimization')\n",
    "        study.optimize(lambda trial: objective(trial, df, feats, seed, model_type), n_trials=trials)\n",
    "\n",
    "        print(f'SEED: {seed}')\n",
    "        print(f'Best_Score: {study.best_value}\\n')\n",
    "        \n",
    "        # 2. [핵심] 고정 파라미터와 최적 파라미터 병합 (Merge)\n",
    "        best_params = study.best_params # Optuna가 찾은 값들\n",
    "        final_params = {}\n",
    "\n",
    "        if model_type == 'lgb':\n",
    "            final_params = {\n",
    "                'objective': 'regression',\n",
    "                'verbosity': -1,\n",
    "                'random_state': seed,\n",
    "                'n_jobs': -1\n",
    "            }\n",
    "            \n",
    "        elif model_type == 'xgb':\n",
    "            final_params = {\n",
    "                'objective': 'reg:squarederror',\n",
    "                'random_state': seed,\n",
    "                'n_jobs': -1,\n",
    "                'enable_categorical': True, \n",
    "                'tree_method': 'hist'\n",
    "            }\n",
    "            \n",
    "        elif model_type == 'hgb':\n",
    "            # HGB는 categorical_features 마스크가 필요함\n",
    "            is_categorical = [f in cat_cols for f in feats]\n",
    "            final_params = {\n",
    "                'loss': 'squared_error',\n",
    "                'categorical_features': is_categorical,\n",
    "                'random_state': seed\n",
    "            }\n",
    "\n",
    "        # 고정 파라미터 딕셔너리에 Optuna 최적 파라미터를 덮어씌움 (Update)\n",
    "        final_params.update(best_params)\n",
    "    \n",
    "        Scores.append(study.best_value)\n",
    "        Params.append(final_params) # 이제 모든 파라미터가 포함됨\n",
    "    \n",
    "    return Scores, Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "400f7ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-28 05:08:01,955] A new study created in memory with name: Optimization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgb 모델 (SEED 1개: [1]), Trial = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-28 05:08:42,724] Trial 0 finished with value: 0.6657517773089668 and parameters: {'n_estimators': 1598, 'learning_rate': 0.0013033619075800964, 'num_leaves': 96, 'max_depth': 12, 'subsample': 0.8501322796399804, 'colsample_bytree': 0.9872881027988333, 'reg_alpha': 0.0024526949421631505, 'reg_lambda': 0.15557166348394752}. Best is trial 0 with value: 0.6657517773089668.\n",
      "[I 2025-11-28 05:08:47,690] Trial 1 finished with value: 0.6018682263710703 and parameters: {'n_estimators': 1555, 'learning_rate': 0.005000071144937592, 'num_leaves': 50, 'max_depth': 4, 'subsample': 0.5778792408349296, 'colsample_bytree': 0.9297809955270023, 'reg_alpha': 0.0026863445187137007, 'reg_lambda': 0.06178734024043109}. Best is trial 1 with value: 0.6018682263710703.\n",
      "[I 2025-11-28 05:08:48,925] Trial 2 finished with value: 0.5885474846918524 and parameters: {'n_estimators': 1891, 'learning_rate': 0.07213024683411125, 'num_leaves': 115, 'max_depth': 3, 'subsample': 0.6492088924237205, 'colsample_bytree': 0.6475948475987867, 'reg_alpha': 0.0022540604718737033, 'reg_lambda': 2.4260768582881975}. Best is trial 2 with value: 0.5885474846918524.\n",
      "[I 2025-11-28 05:09:10,502] Trial 3 finished with value: 0.5862973797676568 and parameters: {'n_estimators': 1009, 'learning_rate': 0.004044692744898088, 'num_leaves': 119, 'max_depth': 11, 'subsample': 0.9045255713064202, 'colsample_bytree': 0.5748854875262011, 'reg_alpha': 7.199745994871632, 'reg_lambda': 0.37424881812395255}. Best is trial 3 with value: 0.5862973797676568.\n",
      "[I 2025-11-28 05:09:12,048] Trial 4 finished with value: 0.568474480776861 and parameters: {'n_estimators': 1418, 'learning_rate': 0.058742163016799714, 'num_leaves': 16, 'max_depth': 7, 'subsample': 0.983033958422803, 'colsample_bytree': 0.528628950550073, 'reg_alpha': 0.4671310098556676, 'reg_lambda': 1.1314013825865474}. Best is trial 4 with value: 0.568474480776861.\n",
      "[I 2025-11-28 05:09:25,942] Trial 5 finished with value: 0.5772027946317394 and parameters: {'n_estimators': 1852, 'learning_rate': 0.006182758026668476, 'num_leaves': 115, 'max_depth': 8, 'subsample': 0.9546594368536042, 'colsample_bytree': 0.9271713947223894, 'reg_alpha': 5.300485370590174, 'reg_lambda': 4.248232568148503}. Best is trial 4 with value: 0.568474480776861.\n",
      "[I 2025-11-28 05:09:48,835] Trial 6 finished with value: 0.5686431857249804 and parameters: {'n_estimators': 1481, 'learning_rate': 0.0066423564338409045, 'num_leaves': 164, 'max_depth': 13, 'subsample': 0.7399512760646301, 'colsample_bytree': 0.6516337948982267, 'reg_alpha': 0.8449724435014598, 'reg_lambda': 0.0022432629686115458}. Best is trial 4 with value: 0.568474480776861.\n",
      "[I 2025-11-28 05:09:52,165] Trial 7 finished with value: 0.5634474405778306 and parameters: {'n_estimators': 1861, 'learning_rate': 0.05069650465124155, 'num_leaves': 86, 'max_depth': 13, 'subsample': 0.7206895652932217, 'colsample_bytree': 0.6743949402835742, 'reg_alpha': 0.007416733156093937, 'reg_lambda': 0.00158252944720565}. Best is trial 7 with value: 0.5634474405778306.\n",
      "[I 2025-11-28 05:10:09,937] Trial 8 finished with value: 0.6503165561315072 and parameters: {'n_estimators': 1634, 'learning_rate': 0.001328779702430534, 'num_leaves': 27, 'max_depth': 11, 'subsample': 0.5466529342035604, 'colsample_bytree': 0.6380220344362117, 'reg_alpha': 0.027700504975082998, 'reg_lambda': 1.7745324139477279}. Best is trial 7 with value: 0.5634474405778306.\n",
      "[I 2025-11-28 05:10:19,444] Trial 9 finished with value: 0.7373455159382836 and parameters: {'n_estimators': 704, 'learning_rate': 0.001514222209257297, 'num_leaves': 114, 'max_depth': 6, 'subsample': 0.6114875970496307, 'colsample_bytree': 0.7370251077295515, 'reg_alpha': 0.013807871615432869, 'reg_lambda': 0.3655092560097006}. Best is trial 7 with value: 0.5634474405778306.\n",
      "[I 2025-11-28 05:10:27,997] Trial 10 finished with value: 0.6008309751016991 and parameters: {'n_estimators': 1035, 'learning_rate': 0.02600351345996316, 'num_leaves': 200, 'max_depth': 15, 'subsample': 0.7624450323072737, 'colsample_bytree': 0.8026275945963783, 'reg_alpha': 0.04696036708489643, 'reg_lambda': 0.0010075091127309099}. Best is trial 7 with value: 0.5634474405778306.\n",
      "[I 2025-11-28 05:10:30,126] Trial 11 finished with value: 0.5644356431303881 and parameters: {'n_estimators': 1337, 'learning_rate': 0.07901791866837352, 'num_leaves': 59, 'max_depth': 8, 'subsample': 0.7650918776271715, 'colsample_bytree': 0.5043894797684664, 'reg_alpha': 0.3732914487758634, 'reg_lambda': 0.019984741643234306}. Best is trial 7 with value: 0.5634474405778306.\n",
      "[I 2025-11-28 05:10:34,503] Trial 12 finished with value: 0.5645245337178003 and parameters: {'n_estimators': 546, 'learning_rate': 0.024937003847610485, 'num_leaves': 69, 'max_depth': 9, 'subsample': 0.7270389942803074, 'colsample_bytree': 0.755684656988753, 'reg_alpha': 0.28882272928179714, 'reg_lambda': 0.011149522969000208}. Best is trial 7 with value: 0.5634474405778306.\n",
      "[I 2025-11-28 05:10:38,147] Trial 13 finished with value: 0.5633068448572832 and parameters: {'n_estimators': 1236, 'learning_rate': 0.033088425159257494, 'num_leaves': 74, 'max_depth': 15, 'subsample': 0.8301901638500659, 'colsample_bytree': 0.5756985984656686, 'reg_alpha': 0.16948979671930547, 'reg_lambda': 0.012883758535332048}. Best is trial 13 with value: 0.5633068448572832.\n",
      "[I 2025-11-28 05:10:42,736] Trial 14 finished with value: 0.5607449300707031 and parameters: {'n_estimators': 1093, 'learning_rate': 0.02859580367837943, 'num_leaves': 81, 'max_depth': 15, 'subsample': 0.842438130309866, 'colsample_bytree': 0.5864775593218708, 'reg_alpha': 0.010754692279039647, 'reg_lambda': 0.0055572210389743144}. Best is trial 14 with value: 0.5607449300707031.\n",
      "[I 2025-11-28 05:10:53,102] Trial 15 finished with value: 0.5611199346876254 and parameters: {'n_estimators': 1103, 'learning_rate': 0.01712796962584816, 'num_leaves': 144, 'max_depth': 15, 'subsample': 0.8316642475839631, 'colsample_bytree': 0.5561609977219543, 'reg_alpha': 0.08516122233828273, 'reg_lambda': 0.007037777681755957}. Best is trial 14 with value: 0.5607449300707031.\n",
      "[I 2025-11-28 05:11:04,917] Trial 16 finished with value: 0.5663547926837289 and parameters: {'n_estimators': 878, 'learning_rate': 0.012873967209662714, 'num_leaves': 143, 'max_depth': 15, 'subsample': 0.8480551909566479, 'colsample_bytree': 0.5751762882396009, 'reg_alpha': 0.06074548553479231, 'reg_lambda': 0.0037868368617631092}. Best is trial 14 with value: 0.5607449300707031.\n",
      "[I 2025-11-28 05:11:16,274] Trial 17 finished with value: 0.5885079051591641 and parameters: {'n_estimators': 1047, 'learning_rate': 0.013150279943850611, 'num_leaves': 149, 'max_depth': 13, 'subsample': 0.8931341965082921, 'colsample_bytree': 0.817167699515822, 'reg_alpha': 0.009179518733437298, 'reg_lambda': 0.04692763996190271}. Best is trial 14 with value: 0.5607449300707031.\n",
      "[I 2025-11-28 05:11:25,663] Trial 18 finished with value: 0.5713205298809637 and parameters: {'n_estimators': 795, 'learning_rate': 0.018786501469147284, 'num_leaves': 181, 'max_depth': 10, 'subsample': 0.671770745485509, 'colsample_bytree': 0.7003703016179718, 'reg_alpha': 1.8152398142694686, 'reg_lambda': 0.004402799866955009}. Best is trial 14 with value: 0.5607449300707031.\n",
      "[I 2025-11-28 05:11:31,627] Trial 19 finished with value: 0.5574234491335498 and parameters: {'n_estimators': 456, 'learning_rate': 0.03693384231048723, 'num_leaves': 139, 'max_depth': 14, 'subsample': 0.7858503809222797, 'colsample_bytree': 0.5874219569650023, 'reg_alpha': 0.11438938899554003, 'reg_lambda': 0.00787313069156912}. Best is trial 19 with value: 0.5574234491335498.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 1\n",
      "Best_Score: 0.5574234491335498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LGB optuna\n",
    "_, lgb_params = training_with_seed(df_train_model, feature_cols, 'lgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d56baae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-28 05:11:31,635] A new study created in memory with name: Optimization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb 모델 (SEED 1개: [1]), Trial = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-28 05:11:35,406] Trial 0 finished with value: 0.5529871227782798 and parameters: {'n_estimators': 1305, 'learning_rate': 0.059238529418810096, 'max_depth': 7, 'subsample': 0.7039388445537336, 'colsample_bytree': 0.7861058574315025, 'reg_alpha': 0.056243531054134766, 'reg_lambda': 0.0102149648426016}. Best is trial 0 with value: 0.5529871227782798.\n",
      "[I 2025-11-28 05:11:39,070] Trial 1 finished with value: 0.5823067686363269 and parameters: {'n_estimators': 479, 'learning_rate': 0.017957939276075707, 'max_depth': 3, 'subsample': 0.8520084718363244, 'colsample_bytree': 0.9730037462792338, 'reg_alpha': 0.2367834693885073, 'reg_lambda': 1.3196764779689176}. Best is trial 0 with value: 0.5529871227782798.\n",
      "[I 2025-11-28 05:12:31,161] Trial 2 finished with value: 0.5632991420388778 and parameters: {'n_estimators': 1581, 'learning_rate': 0.09712937575670637, 'max_depth': 15, 'subsample': 0.572188195655627, 'colsample_bytree': 0.6282691595706034, 'reg_alpha': 4.196530458924404, 'reg_lambda': 0.011583910019287063}. Best is trial 0 with value: 0.5529871227782798.\n",
      "[I 2025-11-28 05:12:37,472] Trial 3 finished with value: 0.5687209031216119 and parameters: {'n_estimators': 580, 'learning_rate': 0.010950023475694081, 'max_depth': 5, 'subsample': 0.8562630256665362, 'colsample_bytree': 0.5073576638130222, 'reg_alpha': 0.6425850827834736, 'reg_lambda': 0.16404118407738436}. Best is trial 0 with value: 0.5529871227782798.\n",
      "[I 2025-11-28 05:12:57,600] Trial 4 finished with value: 0.5711931484645099 and parameters: {'n_estimators': 1653, 'learning_rate': 0.0037070430077949484, 'max_depth': 6, 'subsample': 0.5500738671282885, 'colsample_bytree': 0.9277262350110866, 'reg_alpha': 2.273497007343532, 'reg_lambda': 0.00426763922671702}. Best is trial 0 with value: 0.5529871227782798.\n",
      "[I 2025-11-28 05:13:48,179] Trial 5 finished with value: 0.6255272281270169 and parameters: {'n_estimators': 1105, 'learning_rate': 0.0026069976284590953, 'max_depth': 10, 'subsample': 0.5206963410923953, 'colsample_bytree': 0.8467769866281658, 'reg_alpha': 0.10174920058816436, 'reg_lambda': 1.6363334298992536}. Best is trial 0 with value: 0.5529871227782798.\n",
      "[I 2025-11-28 05:13:55,506] Trial 6 finished with value: 0.5521923684260887 and parameters: {'n_estimators': 519, 'learning_rate': 0.08967070440492603, 'max_depth': 10, 'subsample': 0.5450585181829026, 'colsample_bytree': 0.7179885415041458, 'reg_alpha': 0.02094441920893049, 'reg_lambda': 0.04502412294634913}. Best is trial 6 with value: 0.5521923684260887.\n",
      "[I 2025-11-28 05:17:12,930] Trial 7 finished with value: 0.6162432234680196 and parameters: {'n_estimators': 1823, 'learning_rate': 0.0019201174473825547, 'max_depth': 15, 'subsample': 0.7981904213497789, 'colsample_bytree': 0.7734635279962163, 'reg_alpha': 5.754024517226575, 'reg_lambda': 1.8774263960300224}. Best is trial 6 with value: 0.5521923684260887.\n",
      "[I 2025-11-28 05:17:16,789] Trial 8 finished with value: 0.5478124848346001 and parameters: {'n_estimators': 1869, 'learning_rate': 0.063763979957326, 'max_depth': 7, 'subsample': 0.7249282346669087, 'colsample_bytree': 0.5666612367158472, 'reg_alpha': 2.870231951758219, 'reg_lambda': 0.003286511767142477}. Best is trial 8 with value: 0.5478124848346001.\n",
      "[I 2025-11-28 05:17:24,817] Trial 9 finished with value: 0.5668618206592911 and parameters: {'n_estimators': 1823, 'learning_rate': 0.01369384263878779, 'max_depth': 7, 'subsample': 0.5634224811324338, 'colsample_bytree': 0.6315646352215234, 'reg_alpha': 0.01145200987875771, 'reg_lambda': 0.6742813025851986}. Best is trial 8 with value: 0.5478124848346001.\n",
      "[I 2025-11-28 05:18:01,951] Trial 10 finished with value: 0.5373216238701471 and parameters: {'n_estimators': 953, 'learning_rate': 0.032010238009474494, 'max_depth': 12, 'subsample': 0.9538423552611874, 'colsample_bytree': 0.5320927348618072, 'reg_alpha': 0.0016650736805284775, 'reg_lambda': 0.0016727768169412635}. Best is trial 10 with value: 0.5373216238701471.\n",
      "[I 2025-11-28 05:18:40,748] Trial 11 finished with value: 0.521296992885136 and parameters: {'n_estimators': 913, 'learning_rate': 0.03357654503973482, 'max_depth': 12, 'subsample': 0.9990442425430429, 'colsample_bytree': 0.5325145799921995, 'reg_alpha': 0.0011005838240873507, 'reg_lambda': 0.0010042443811865832}. Best is trial 11 with value: 0.521296992885136.\n",
      "[I 2025-11-28 05:19:20,415] Trial 12 finished with value: 0.5365635033408916 and parameters: {'n_estimators': 885, 'learning_rate': 0.028786026500541267, 'max_depth': 12, 'subsample': 0.9954818577681641, 'colsample_bytree': 0.5032507543996959, 'reg_alpha': 0.001079454196295075, 'reg_lambda': 0.0011409198564347638}. Best is trial 11 with value: 0.521296992885136.\n",
      "[I 2025-11-28 05:20:01,462] Trial 13 finished with value: 0.5685041096666038 and parameters: {'n_estimators': 797, 'learning_rate': 0.030526454916496457, 'max_depth': 12, 'subsample': 0.9800913384405016, 'colsample_bytree': 0.6243500556129298, 'reg_alpha': 0.0010334248781597583, 'reg_lambda': 0.001154167011436894}. Best is trial 11 with value: 0.521296992885136.\n",
      "[I 2025-11-28 05:21:41,910] Trial 14 finished with value: 0.5855436724595017 and parameters: {'n_estimators': 809, 'learning_rate': 0.0059020000233623105, 'max_depth': 13, 'subsample': 0.915962374833278, 'colsample_bytree': 0.6881633061203077, 'reg_alpha': 0.0049629318189028954, 'reg_lambda': 0.03492050404210782}. Best is trial 11 with value: 0.521296992885136.\n",
      "[I 2025-11-28 05:22:25,404] Trial 15 finished with value: 0.547293300706882 and parameters: {'n_estimators': 1295, 'learning_rate': 0.03175946769370101, 'max_depth': 13, 'subsample': 0.9857029602288175, 'colsample_bytree': 0.5718789235321796, 'reg_alpha': 0.0032775817232472714, 'reg_lambda': 0.17244092598645208}. Best is trial 11 with value: 0.521296992885136.\n",
      "[I 2025-11-28 05:22:34,946] Trial 16 finished with value: 0.5491257005426693 and parameters: {'n_estimators': 1085, 'learning_rate': 0.022404209446872776, 'max_depth': 9, 'subsample': 0.8944486166958421, 'colsample_bytree': 0.5073451515868189, 'reg_alpha': 0.009539543613454568, 'reg_lambda': 7.846260063491902}. Best is trial 11 with value: 0.521296992885136.\n",
      "[I 2025-11-28 05:23:27,054] Trial 17 finished with value: 0.5642429940777365 and parameters: {'n_estimators': 738, 'learning_rate': 0.007448634450571737, 'max_depth': 11, 'subsample': 0.6495084165171024, 'colsample_bytree': 0.5788144793226754, 'reg_alpha': 0.0010263845501488468, 'reg_lambda': 0.008435992323980176}. Best is trial 11 with value: 0.521296992885136.\n",
      "[I 2025-11-28 05:24:38,814] Trial 18 finished with value: 0.5648766039176852 and parameters: {'n_estimators': 952, 'learning_rate': 0.04828453981190142, 'max_depth': 14, 'subsample': 0.7870336122262075, 'colsample_bytree': 0.6733446704228101, 'reg_alpha': 0.03557030984793424, 'reg_lambda': 0.001213343532812421}. Best is trial 11 with value: 0.521296992885136.\n",
      "[I 2025-11-28 05:25:35,683] Trial 19 finished with value: 0.7173062634232412 and parameters: {'n_estimators': 1384, 'learning_rate': 0.0010289397763649458, 'max_depth': 9, 'subsample': 0.8984353565123143, 'colsample_bytree': 0.8384185877921538, 'reg_alpha': 0.0033202716022133695, 'reg_lambda': 0.028958465191479175}. Best is trial 11 with value: 0.521296992885136.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 1\n",
      "Best_Score: 0.521296992885136\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XGB optuna\n",
    "_, xgb_params = training_with_seed(df_train_model, feature_cols, 'xgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1a90acfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-28 05:25:35,691] A new study created in memory with name: Optimization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hgb 모델 (SEED 1개: [1]), Trial = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-28 05:27:20,618] Trial 0 finished with value: 0.6567858860725041 and parameters: {'max_iter': 926, 'learning_rate': 0.0023954644383620055, 'max_depth': 12, 'max_leaf_nodes': 144, 'l2_regularization': 0.42233371806503495}. Best is trial 0 with value: 0.6567858860725041.\n",
      "[I 2025-11-28 05:28:14,524] Trial 1 finished with value: 0.4713051315611811 and parameters: {'max_iter': 985, 'learning_rate': 0.0932455122647868, 'max_depth': 12, 'max_leaf_nodes': 84, 'l2_regularization': 0.1299384387562076}. Best is trial 1 with value: 0.4713051315611811.\n",
      "[I 2025-11-28 05:29:11,381] Trial 2 finished with value: 0.45643860534984243 and parameters: {'max_iter': 709, 'learning_rate': 0.01897622000118871, 'max_depth': 15, 'max_leaf_nodes': 92, 'l2_regularization': 0.27641080971811927}. Best is trial 2 with value: 0.45643860534984243.\n",
      "[I 2025-11-28 05:29:35,951] Trial 3 finished with value: 0.49086689386229243 and parameters: {'max_iter': 959, 'learning_rate': 0.01136662167790142, 'max_depth': 4, 'max_leaf_nodes': 159, 'l2_regularization': 0.0019460261649479036}. Best is trial 2 with value: 0.45643860534984243.\n",
      "[I 2025-11-28 05:30:28,375] Trial 4 finished with value: 0.4576445704895884 and parameters: {'max_iter': 735, 'learning_rate': 0.09023411481498281, 'max_depth': 14, 'max_leaf_nodes': 118, 'l2_regularization': 0.24080165612098417}. Best is trial 2 with value: 0.45643860534984243.\n",
      "[I 2025-11-28 05:32:37,025] Trial 5 finished with value: 0.48288490839253545 and parameters: {'max_iter': 1862, 'learning_rate': 0.0031566860351409268, 'max_depth': 11, 'max_leaf_nodes': 88, 'l2_regularization': 2.723075996168923}. Best is trial 2 with value: 0.45643860534984243.\n",
      "[I 2025-11-28 05:33:24,079] Trial 6 finished with value: 0.4783679811047649 and parameters: {'max_iter': 1052, 'learning_rate': 0.006673711137463675, 'max_depth': 8, 'max_leaf_nodes': 49, 'l2_regularization': 1.6823893171000877}. Best is trial 2 with value: 0.45643860534984243.\n",
      "[I 2025-11-28 05:35:21,623] Trial 7 finished with value: 0.6173775508621078 and parameters: {'max_iter': 1120, 'learning_rate': 0.002426866729210828, 'max_depth': 10, 'max_leaf_nodes': 146, 'l2_regularization': 0.12287650309694609}. Best is trial 2 with value: 0.45643860534984243.\n",
      "[I 2025-11-28 05:35:45,483] Trial 8 finished with value: 0.4675369844128748 and parameters: {'max_iter': 581, 'learning_rate': 0.0731726685276579, 'max_depth': 7, 'max_leaf_nodes': 37, 'l2_regularization': 0.0010498566881266787}. Best is trial 2 with value: 0.45643860534984243.\n",
      "[I 2025-11-28 05:37:07,153] Trial 9 finished with value: 0.46510492158132255 and parameters: {'max_iter': 1034, 'learning_rate': 0.05665200722056741, 'max_depth': 10, 'max_leaf_nodes': 155, 'l2_regularization': 0.0013905103683280956}. Best is trial 2 with value: 0.45643860534984243.\n",
      "[I 2025-11-28 05:37:40,414] Trial 10 finished with value: 0.4722646108532338 and parameters: {'max_iter': 1511, 'learning_rate': 0.02182424784401407, 'max_depth': 15, 'max_leaf_nodes': 11, 'l2_regularization': 0.011719702393982954}. Best is trial 2 with value: 0.45643860534984243.\n",
      "[I 2025-11-28 05:38:28,576] Trial 11 finished with value: 0.4555125902906468 and parameters: {'max_iter': 556, 'learning_rate': 0.02798002610989338, 'max_depth': 15, 'max_leaf_nodes': 112, 'l2_regularization': 0.02780976287989237}. Best is trial 11 with value: 0.4555125902906468.\n",
      "[I 2025-11-28 05:39:15,411] Trial 12 finished with value: 0.4545077238185123 and parameters: {'max_iter': 547, 'learning_rate': 0.026287797683506576, 'max_depth': 15, 'max_leaf_nodes': 110, 'l2_regularization': 0.01866796588834305}. Best is trial 12 with value: 0.4545077238185123.\n",
      "[I 2025-11-28 05:40:07,136] Trial 13 finished with value: 0.45544524807960923 and parameters: {'max_iter': 421, 'learning_rate': 0.034092958831437314, 'max_depth': 13, 'max_leaf_nodes': 191, 'l2_regularization': 0.020931537431571067}. Best is trial 12 with value: 0.4545077238185123.\n",
      "[I 2025-11-28 05:41:01,467] Trial 14 finished with value: 0.4598202224973232 and parameters: {'max_iter': 438, 'learning_rate': 0.03899475978471536, 'max_depth': 13, 'max_leaf_nodes': 196, 'l2_regularization': 0.014883483700645956}. Best is trial 12 with value: 0.4545077238185123.\n",
      "[I 2025-11-28 05:42:05,080] Trial 15 finished with value: 0.7052274065557559 and parameters: {'max_iter': 1396, 'learning_rate': 0.0011249772629378307, 'max_depth': 6, 'max_leaf_nodes': 200, 'l2_regularization': 0.005418166973749864}. Best is trial 12 with value: 0.4545077238185123.\n",
      "[I 2025-11-28 05:42:36,199] Trial 16 finished with value: 0.49650724282346514 and parameters: {'max_iter': 474, 'learning_rate': 0.011008392688944522, 'max_depth': 13, 'max_leaf_nodes': 67, 'l2_regularization': 0.044593015178355004}. Best is trial 12 with value: 0.4545077238185123.\n",
      "[I 2025-11-28 05:44:01,855] Trial 17 finished with value: 0.4586400851416225 and parameters: {'max_iter': 758, 'learning_rate': 0.040542696049591376, 'max_depth': 13, 'max_leaf_nodes': 178, 'l2_regularization': 0.004980607816170053}. Best is trial 12 with value: 0.4545077238185123.\n",
      "[I 2025-11-28 05:44:28,860] Trial 18 finished with value: 0.5045594075968997 and parameters: {'max_iter': 1307, 'learning_rate': 0.006754144858843109, 'max_depth': 3, 'max_leaf_nodes': 128, 'l2_regularization': 0.047003479355746114}. Best is trial 12 with value: 0.4545077238185123.\n",
      "[I 2025-11-28 05:46:51,061] Trial 19 finished with value: 0.46069210215275613 and parameters: {'max_iter': 1753, 'learning_rate': 0.019670047369686583, 'max_depth': 9, 'max_leaf_nodes': 176, 'l2_regularization': 0.004508200692819832}. Best is trial 12 with value: 0.4545077238185123.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 1\n",
      "Best_Score: 0.4545077238185123\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# HGB optuna\n",
    "_, hgb_params = training_with_seed(df_train_model, feature_cols, 'hgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d21fbaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추가 모델 정의 (Linear, Ridge, Lasso, MLP)\n",
    "X = df_train_model[feature_cols].copy()\n",
    "y = df_train_model['target'].copy()\n",
    "\n",
    "numeric_features = [\"time\", \"b_t\", \"b_t_1\", \"b_w_t\", \"b_w_t_1\", \"a_t_lag\", \"a_w_t_lag\", \"max_corr\", \"best_lag\"]\n",
    "categorical_features = [\"a_hs2\", \"b_hs2\", \"a_hs4\", \"b_hs4\"]\n",
    "\n",
    "# 데이터 전처리\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "linear_model = Pipeline([('preprocessor', preprocessor), ('regressor', LinearRegression())])\n",
    "ridge_model = Pipeline([('preprocessor', preprocessor), ('regressor', Ridge(alpha=1.0))])\n",
    "lasso_model = Pipeline([('preprocessor', preprocessor), ('regressor', Lasso(alpha=0.01))])\n",
    "mlp_model = Pipeline([('preprocessor', preprocessor), ('regressor', MLPRegressor(hidden_layer_sizes=(64, 32), max_iter=500, random_state=42))])\n",
    "\n",
    "additional_models = {\n",
    "    'linear': linear_model,\n",
    "    'ridge': ridge_model,\n",
    "    'lasso': lasso_model,\n",
    "    'mlp': mlp_model\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "dd658b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 모델 앙상블 및 잔차 학습 모델 추가\n",
    "class FinalHybridModel:\n",
    "    def __init__(self, lgb_params_list, xgb_params_list, hgb_params_list, additional_models, weights=None):\n",
    "        self.lgb_params = lgb_params_list\n",
    "        self.xgb_params = xgb_params_list\n",
    "        self.hgb_params = hgb_params_list\n",
    "        self.add_models = additional_models\n",
    "        \n",
    "        self.trained_lgb = []\n",
    "        self.trained_xgb = []\n",
    "        self.trained_hgb = []\n",
    "        self.trained_add = {}\n",
    "        \n",
    "        self.residual_model = None\n",
    "        \n",
    "        if weights is None:\n",
    "            self.weights = {\n",
    "                'lgb': 3.0, 'xgb': 3.0, 'hgb': 2.0,\n",
    "                'linear': 0.5, 'ridge': 0.5, 'lasso': 0.5, 'mlp': 1.0\n",
    "            }\n",
    "        else:\n",
    "            self.weights = weights\n",
    "\n",
    "    def fit(self, X, y, use_residual=True): # 학습\n",
    "        print(\"===== 1. Start Training Base Models with Time Weights =====\")\n",
    "        \n",
    "        # 시간 가중치 계산\n",
    "        times = X['time']\n",
    "        min_time = times.min()\n",
    "        max_time = times.max()\n",
    "        denom = max_time - min_time\n",
    "        \n",
    "        norm_time = (times - min_time) / denom\n",
    "        sample_weight = np.exp(norm_time * 3).values\n",
    "        \n",
    "        # -------------------------------------------------------\n",
    "        \n",
    "        # 2) LGBM\n",
    "        print(f\"Training {len(self.lgb_params)} LGBM Seed Models...\")\n",
    "        for params in self.lgb_params:\n",
    "            model = LGBMRegressor(**params)\n",
    "            model.fit(X, y, sample_weight=sample_weight) \n",
    "            self.trained_lgb.append(model)\n",
    "            \n",
    "        # 3) XGB\n",
    "        print(f\"Training {len(self.xgb_params)} XGB Seed Models...\")\n",
    "        for params in self.xgb_params:\n",
    "            params['enable_categorical'] = True\n",
    "            params['tree_method'] = 'hist'\n",
    "            model = XGBRegressor(**params)\n",
    "            model.fit(X, y, sample_weight=sample_weight, verbose=False)\n",
    "            self.trained_xgb.append(model)\n",
    "            \n",
    "        # 4) HGB\n",
    "        print(f\"Training {len(self.hgb_params)} HGB Seed Models...\")\n",
    "        for params in self.hgb_params:\n",
    "            model = HistGradientBoostingRegressor(**params)\n",
    "            # [수정] sample_weight 전달\n",
    "            model.fit(X, y, sample_weight=sample_weight)\n",
    "            self.trained_hgb.append(model)\n",
    "            \n",
    "        # 5) Additional Models Training\n",
    "        print(\"Training Additional Models...\")\n",
    "        for name, model in self.add_models.items():\n",
    "            print(f\" - Fitting {name}...\")\n",
    "            \n",
    "            if name == 'mlp':\n",
    "                model.fit(X, y)\n",
    "            else:\n",
    "                try:\n",
    "                    model.fit(X, y, regressor__sample_weight=sample_weight)\n",
    "                except:\n",
    "                    print(f\"   (Warning: {name} fit without weights)\")\n",
    "                    model.fit(X, y)\n",
    "                    \n",
    "            self.trained_add[name] = model\n",
    "            \n",
    "        # 6) Residual Learning\n",
    "        if use_residual:\n",
    "            print(\"===== 2. Start Residual Learning =====\")\n",
    "            base_preds = self._predict_voting(X)\n",
    "            residuals = y - base_preds\n",
    "            \n",
    "            print(\"Fitting Residual Model (LGBM)...\")\n",
    "            res_params = {\n",
    "                'n_estimators': 300, 'learning_rate': 0.01, 'max_depth': 3,\n",
    "                'random_state': 42, 'n_jobs': -1, 'verbosity': -1, 'reg_alpha': 1.0\n",
    "            }\n",
    "            self.residual_model = LGBMRegressor(**res_params)\n",
    "            self.residual_model.fit(X, residuals, sample_weight=sample_weight)\n",
    "            \n",
    "        print(\"===== Training Completed =====\")\n",
    "\n",
    "    def _predict_voting(self, X):\n",
    "        # (기존 코드와 동일)\n",
    "        pred_lgb = np.mean([m.predict(X) for m in self.trained_lgb], axis=0)\n",
    "        pred_xgb = np.mean([m.predict(X) for m in self.trained_xgb], axis=0)\n",
    "        pred_hgb = np.mean([m.predict(X) for m in self.trained_hgb], axis=0)\n",
    "        \n",
    "        pred_add = {}\n",
    "        for name, model in self.trained_add.items():\n",
    "            pred_add[name] = model.predict(X)\n",
    "            \n",
    "        final_pred = (\n",
    "            pred_lgb * self.weights['lgb'] +\n",
    "            pred_xgb * self.weights['xgb'] +\n",
    "            pred_hgb * self.weights['hgb'] +\n",
    "            pred_add['linear'] * self.weights['linear'] +\n",
    "            pred_add['ridge'] * self.weights['ridge'] +\n",
    "            pred_add['lasso'] * self.weights['lasso'] +\n",
    "            pred_add['mlp'] * self.weights['mlp']\n",
    "        )\n",
    "        return final_pred / sum(self.weights.values())\n",
    "\n",
    "    def predict(self, X):\n",
    "        base_pred = self._predict_voting(X)\n",
    "        if self.residual_model is not None:\n",
    "            res_pred = self.residual_model.predict(X)\n",
    "            return base_pred + res_pred\n",
    "        return base_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c4519778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== 1. Start Training Base Models with Time Weights =====\n",
      "Training 1 LGBM Seed Models...\n",
      "Training 1 XGB Seed Models...\n",
      "Training 1 HGB Seed Models...\n",
      "Training Additional Models...\n",
      " - Fitting linear...\n",
      " - Fitting ridge...\n",
      " - Fitting lasso...\n",
      " - Fitting mlp...\n",
      "===== 2. Start Residual Learning =====\n",
      "Fitting Residual Model (LGBM)...\n",
      "===== Training Completed =====\n"
     ]
    }
   ],
   "source": [
    "# 앙상블 모델 학습\n",
    "voting_weights = {\n",
    "    'lgb': 0.5, 'xgb': 0.5, 'hgb': 4.0,\n",
    "    'linear': 0.5, 'ridge': 0.5, 'lasso': 0.5, 'mlp': 3.5\n",
    "}\n",
    "\n",
    "final_model = FinalHybridModel(\n",
    "    lgb_params_list=lgb_params, \n",
    "    xgb_params_list=xgb_params, \n",
    "    hgb_params_list=hgb_params, \n",
    "    additional_models=additional_models,\n",
    "    weights=voting_weights\n",
    ")\n",
    "\n",
    "final_model.fit(X, y, use_residual=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "58a03183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Final Predictions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3001/3001 [01:33<00:00, 32.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 예측 완료\n",
      "  leading_item_id following_item_id     value\n",
      "0        AHMDUILJ          APQGTRMF    105191\n",
      "1        AHMDUILJ          ATLDMDBO  70630515\n",
      "2        AHMDUILJ          AXULOHBQ     79749\n",
      "3        AHMDUILJ          BJALXPFS    163597\n",
      "4        AHMDUILJ          BSRMSVTC    244025\n"
     ]
    }
   ],
   "source": [
    "def predict_final_submission(pivot_val, pivot_wgt, pairs, final_model, df):\n",
    "    months = pivot_val.columns.to_list()\n",
    "    n_months = len(months)\n",
    "\n",
    "    t_last = n_months-1 # 2025-07\n",
    "    t_prev = n_months-2 # 2025-06\n",
    "\n",
    "    cat_cols = ['a_hs2', 'b_hs2', 'a_hs4', 'b_hs4']\n",
    "    feature_cols = [\"time\", \"b_t\", \"b_t_1\", \"b_w_t\", \"b_w_t_1\", \"a_t_lag\", \"a_w_t_lag\", \"max_corr\", \"best_lag\", \"a_hs2\", \"b_hs2\", \"a_hs4\", \"b_hs4\"]\n",
    "\n",
    "    preds = []\n",
    "\n",
    "    print(\"Generating Final Predictions...\")\n",
    "    for row in tqdm(pairs.itertuples(index=False), total=len(pairs)):\n",
    "        leader = row.leading_item_id\n",
    "        follower = row.following_item_id\n",
    "        lag = int(row.best_lag)\n",
    "        corr = float(row.max_corr)\n",
    "\n",
    "        # 데이터 유효성 검사\n",
    "        if leader not in pivot_val.index or follower not in pivot_val.index:\n",
    "            continue\n",
    "\n",
    "        a_series_val = pivot_val.loc[leader].values.astype(float)\n",
    "        a_series_wgt = pivot_wgt.loc[leader].values.astype(float)\n",
    "\n",
    "        b_series_val = pivot_val.loc[follower].values.astype(float)\n",
    "        b_series_wgt = pivot_wgt.loc[follower].values.astype(float)\n",
    "\n",
    "        # HS 코드 추출 (df 원본 참조)\n",
    "        a_hs4 = df.loc[df['item_id'] == leader, 'hs4'].iloc[0]\n",
    "        b_hs4 = df.loc[df['item_id'] == follower, 'hs4'].iloc[0]\n",
    "            \n",
    "        a_hs2 = str(a_hs4)[:2]\n",
    "        b_hs2 = str(b_hs4)[:2]\n",
    "        a_hs4 = str(a_hs4)\n",
    "        b_hs4 = str(b_hs4)\n",
    "        \n",
    "        # Lag 범위 체크\n",
    "        if t_last - lag < 0:\n",
    "            continue\n",
    "            \n",
    "        b_t = b_series_val[t_last]\n",
    "        b_t_1 = b_series_val[t_prev]\n",
    "        b_w_t = b_series_wgt[t_last]\n",
    "        b_w_t_1 = b_series_wgt[t_prev]\n",
    "        \n",
    "        a_t_lag = a_series_val[t_last - lag]\n",
    "        a_w_t_lag = a_series_wgt[t_last - lag]\n",
    "\n",
    "        # DataFrame 형태로 입력 생성 (컬럼 순서 및 이름 일치 필수)\n",
    "        input_row = pd.DataFrame([{\n",
    "            \"time\": t_last, # 2025-07 시점\n",
    "            \"b_t\": b_t, \n",
    "            \"b_t_1\": b_t_1,\n",
    "            \"b_w_t\": b_w_t, \n",
    "            \"b_w_t_1\": b_w_t_1, \n",
    "            \"a_t_lag\": a_t_lag, \n",
    "            \"a_w_t_lag\": a_w_t_lag, \n",
    "            \"max_corr\": corr, \n",
    "            \"best_lag\": float(lag), \n",
    "            \"b_hs2\": b_hs2,\n",
    "            \"a_hs2\": a_hs2,\n",
    "            \"a_hs4\": a_hs4, \n",
    "            \"b_hs4\": b_hs4,\n",
    "        }])\n",
    "        \n",
    "        # 학습 때 사용한 컬럼 순서로 정렬 (안전장치)\n",
    "        input_row = input_row[feature_cols] # feature_cols에 hs2가 없다면 위 dict에서 제외 필요\n",
    "        for c in cat_cols:\n",
    "            input_row[c] = input_row[c].astype('category')\n",
    "\n",
    "        # 예측 수행\n",
    "        y_pred = final_model.predict(input_row)[0]\n",
    "\n",
    "        # 후처리 (음수 제거 및 반올림)\n",
    "        y_pred = max(0.0, float(y_pred))\n",
    "        y_pred = int(round(y_pred))\n",
    "\n",
    "        preds.append({\n",
    "            \"leading_item_id\": leader,\n",
    "            \"following_item_id\": follower,\n",
    "            \"value\": y_pred,\n",
    "        })\n",
    "\n",
    "    submission_df = pd.DataFrame(preds)\n",
    "    return submission_df\n",
    "\n",
    "\n",
    "final_submission = predict_final_submission(pivot_val, pivot_wgt, pairs, final_model, train)\n",
    "\n",
    "print(\"최종 예측 완료\")\n",
    "print(final_submission.head())\n",
    "\n",
    "# 저장\n",
    "final_submission.to_csv(\"final_submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
